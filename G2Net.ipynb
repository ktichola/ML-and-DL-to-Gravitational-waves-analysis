{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 23249,
          "databundleVersionId": 2399555,
          "sourceType": "competition"
        },
        {
          "sourceId": 3566200,
          "sourceType": "datasetVersion",
          "datasetId": 2140084
        },
        {
          "sourceId": 3618141,
          "sourceType": "datasetVersion",
          "datasetId": 2168230
        }
      ],
      "dockerImageVersionId": 30140,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "G2Net",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktichola/ML-and-DL-to-Gravitational-waves-analysis/blob/main/G2Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'g2net-gravitational-wave-detection:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F23249%2F2399555%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240505%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240505T085836Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D97d08f178adb6260e90b29c8ae528ca1770f0b2e47cb9d1b4bfbbc2d0726404f4c123ec26312cecd3eadfaf0bd38f5ba01259af2d2ad4e300982007daa5d3f55530f5bbb8f8e19f8bd791098062f17863e0f3ee5c503c9e9b069d0dc9284934a90c04292d23ddc8ca8d25d3761bec39346903e51048dc4ef87f344f7a555a3600f7330654a155a7b318f1d89a8374f67618fcb124ab54e7e9ea57a9227e3d2ad75f86b02e75aad52461ca7ec56b9007b9ebe94c5fea36ce093d91449a4ba088bf9ff42f25eced81a50a70332bf493f42860152c40bc65c7a5c8c516eeefdf8ffd0c68d8efbffeac3d779c12712f81d8044a6497940a65de4c941e96429cb33b4'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "gE5e6eny-hDe"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading time: 10 minutes"
      ],
      "metadata": {
        "id": "4IhC80-J-hDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- IMPORTS --------------------\n",
        "\n",
        "import os\n",
        "import time\n",
        "import psutil\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from scipy import signal\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.signal.windows import hamming, tukey\n",
        "from scipy.signal import butter, filtfilt, sosfiltfilt\n",
        "from statistics import mean\n",
        "from scipy.fft import fft, fftfreq\n",
        "from matplotlib import pyplot as plt\n",
        "from multiprocessing import SimpleQueue, Process\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import stack\n",
        "import tensorflow as tf\n",
        "from scipy.signal import spectrogram\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import EfficientNetB0"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-05-05T08:51:26.62805Z",
          "iopub.execute_input": "2024-05-05T08:51:26.628408Z",
          "iopub.status.idle": "2024-05-05T08:51:33.278028Z",
          "shell.execute_reply.started": "2024-05-05T08:51:26.628313Z",
          "shell.execute_reply": "2024-05-05T08:51:33.277246Z"
        },
        "trusted": true,
        "id": "hFBOBm1y-hDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- CONFIG --------------------\n",
        "\n",
        "# Data loading paths\n",
        "DATA_PATH = '../input/g2net-gravitational-wave-detection/train'\n",
        "submission_data_path = '../input/g2net-gravitational-wave-detection/test'\n",
        "labels_path = '../input/g2net-gravitational-wave-detection/training_labels.csv'\n",
        "\n",
        "# Parameters\n",
        "batch_size = 200\n",
        "learning_rate = 1e-4\n",
        "epochs = 1\n",
        "\n",
        "# Constants\n",
        "INPUT_DIM = (150, 150, 3)\n",
        "SAMPLE_RATE = 2048"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-05-05T08:51:33.279863Z",
          "iopub.execute_input": "2024-05-05T08:51:33.280673Z",
          "iopub.status.idle": "2024-05-05T08:51:33.286381Z",
          "shell.execute_reply.started": "2024-05-05T08:51:33.280622Z",
          "shell.execute_reply": "2024-05-05T08:51:33.285471Z"
        },
        "trusted": true,
        "id": "gByYWMEL-hDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About the project"
      ],
      "metadata": {
        "id": "rkuMedPM-hDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective of the analysis\n",
        "\n",
        "To sum up, this competition tasks us to operate a binary classification where given a signal, we are to predict if a gravitational wave is in there or not.\n",
        "\n",
        "I am not going to show basic EDA for this dataset, as it has already been presented in various notebooks. However, I will still mention that we are given a dataset with two very important characteristics. It has a lot of elements, and both classes are balanced. We can say it fulfills the requirements of both volume and balance, which are precisely the weaknesses I had to work on with previous datasets I have studied on Kaggle.\n",
        "\n",
        "What is missing then ?  Well in a word, quality. This analysis was indeed very instructive about the importance of understanding the data and preprocessing it correctly in order to make the most out of it. Which is not something I did from the start ! I made the mistake of going straight for the search of algorithms to treat the problem, without giving a proper thought about the data. As you will see, this mistake did cost me a lot of time."
      ],
      "metadata": {
        "id": "Yz1jhAPR-hDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sources\n",
        "\n",
        "Overall analysis by Laura Fink in her very detailed notebook. This was clearly a lifesaver in my case, as I struggled with finding ways to start going into signal analysis. All the basics can be find there as well as instructive links to understand the data.\n",
        "https://www.kaggle.com/code/allunia/signal-where-are-you\n",
        "\n",
        "The competition corresponding paper link : https://arxiv.org/pdf/1908.11170.pdf\n",
        "\n",
        "Another very complete notebook by Geir Drange whose approach of the data analysis inspired me greatly. It was also a nice way to discover about the wavelet transform.\n",
        "https://www.kaggle.com/code/mistag/wavelet1d-custom-keras-wavelet-transform-layer\n",
        "\n",
        "About signal analysis, I ended up watching the excellent series of Steve Brunton on Fourier Analysis. His YouTube channel is a gold mine on this topic.\n",
        "https://www.youtube.com/c/Eigensteve\n",
        "\n",
        "On a more technical note, I discovered Keras with « Deep Learning with Python » by François Chollet. In this book I learnt about data generators, which were until recently the only way I knew to load vast amounts of data that cannot fit all at once in memory for training models. But in the very good notebook by Esrat Maria I saw a Tensorflow Dataset pipeline and while searching about it, I found it a very useful tool for our problem.\n",
        "https://www.kaggle.com/code/esratmaria/gravitational-wave-detection-simple-cnn-model\n",
        "\n",
        "A nice tutorial about Tensorflow data pipeline: https://youtube.com/watch?v=VFEOskzhhbc\n"
      ],
      "metadata": {
        "id": "4pHnJYm9-hDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sections presentation\n",
        "\n",
        "We are all set !\n",
        "\n",
        "In this article I will first present my many mistakes going into the analysis. As Yoda said « The greatest teacher, failure is » (what’s a science topic article without a nerd reference right ?).\n",
        "\n",
        "That being said, I then proceed to present a more solide approach based on the various sources listed above. Briefly, it uses Fourier transforms to interpret signals as an RGB image where each channel is a detector spectrogram.\n",
        "\n",
        "Finally, I try to improve preprocessing further in order to obtain better results mostly by changing a few choices made in the previous section."
      ],
      "metadata": {
        "id": "ouiW9soh-hDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From zero to her… zero !\n",
        "\n",
        "Last chance for you to skip ahead, this part of the article is not for soft eyes, you are warned ! More seriously you should actually skip that part if you only want to know about working approaches, this really is a « what not to do » section."
      ],
      "metadata": {
        "id": "_gugerig-hDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero preprocessing - brut force tries on raw data\n",
        "\n",
        "I did warn you, this is not pretty. My first attempt was exactly as the title announces it: I took the raw signal, and shove it through various types of networks to see what happens. Silly right ? I was even showing perseverance as I tried almost every type of networks I know about. Dense network, CNN, LSTM, Gradient Boosting, Random Forest, SVM… No happy ending here, as you expect it gave a fantastic result of 50% accuracy. When all your work is worth as much as a coin flip, it should be a sign don’t you think ?\n",
        "\n",
        "Spoiler alert, combining multiple types of networks with stacking did not help either. So much time designing complex blocs of machine learning, with no improvement whatsoever."
      ],
      "metadata": {
        "id": "f4agQbQC-hDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Features extraction\n",
        "\n",
        "Denile ! At this point it is the only word that accurately describes my thought process. I started to realize that the problem was maybe residing with the way I handled the data, and not the way I handled models and training. Sadly I went in the wrong direction again, keeping the raw signal, and making additional features out of it.\n",
        "\n",
        "Features extracted for each detector were the following:\n",
        "* Frequencies\n",
        "* First degree differentiate\n",
        "* Curve similarity with other detectors\n",
        "* Spectrum\n",
        "\n",
        "Yet even when treated individually or combined together in a single complex model, no results.\n",
        "\n",
        "*-- features generator code below --*"
      ],
      "metadata": {
        "id": "0Y4XsJWO-hDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- UTILS --------------------\n",
        "\n",
        "# Transform signal from time domain to frequency domain\n",
        "def time_to_frequency(signal, sample_rate):\n",
        "    n = len(signal)\n",
        "    yf = fft(signal)\n",
        "    yf = 2.0/n * np.abs(yf[0:n//2])\n",
        "    # xf = fftfreq(n, sample_rate)[:n//2]\n",
        "    return yf\n",
        "\n",
        "\n",
        "# Transform signal from time series to spectrum image\n",
        "def time_to_spectrum(signal_npy, sample_rate):\n",
        "    f, t, Sxx = signal.spectrogram(signal_npy, sample_rate)\n",
        "    return f, t, Sxx\n",
        "\n",
        "\n",
        "# Numerical differentiation\n",
        "def numerical_differentiation(signal: np.array):\n",
        "    n = len(signal)\n",
        "    differentiated_signal = signal[1:] - signal[:(n-1)]\n",
        "    return differentiated_signal\n",
        "\n",
        "\n",
        "# --------------- CUSTOM GENERATOR --------------------\n",
        "\n",
        "class CustomGenerator:\n",
        "\n",
        "    from tensorflow.python.keras.utils.data_utils import Sequence\n",
        "\n",
        "    def __init__(self, inputs_path: list, labels: list, batch_size: int, input_size: tuple, scalers: dict,\n",
        "                 model_class: str, shuffle=True):\n",
        "        self.generator = self.Generator(inputs_path, labels, batch_size, input_size, scalers, model_class, shuffle)\n",
        "\n",
        "    class Generator(Sequence):\n",
        "\n",
        "        def __init__(self, inputs_path: list, labels: list, batch_size: int, input_size: tuple, scalers: dict,\n",
        "                     model_class: str, shuffle=True):\n",
        "\n",
        "            self.inputs_path = inputs_path\n",
        "            self.labels = np.asarray(labels, dtype=int)\n",
        "            self.batch_size = batch_size\n",
        "            self.input_size = input_size\n",
        "            self.shuffle = shuffle\n",
        "            self.nb_inputs = len(inputs_path)\n",
        "            self.categories = len(np.unique(self.labels))\n",
        "            self.scalers = scalers\n",
        "            self.model_class = model_class\n",
        "            self.n = 0\n",
        "            self.max = self.__len__()\n",
        "\n",
        "        def on_epoch_end(self):\n",
        "            if self.shuffle:\n",
        "                np.random.shuffle(self.inputs_path)\n",
        "\n",
        "        def _yield_ish(self, index):\n",
        "            X_path = self.inputs_path[index * self.batch_size: (index + 1) * self.batch_size]\n",
        "            inputs = {\n",
        "                'detector_1_time_input': [],\n",
        "                'detector_2_time_input': [],\n",
        "                'detector_3_time_input': [],\n",
        "                'detector_1_frequency_input': [],\n",
        "                'detector_2_frequency_input': [],\n",
        "                'detector_3_frequency_input': [],\n",
        "                'detector_1_time_differentiate_input': [],\n",
        "                'detector_2_time_differentiate_input': [],\n",
        "                'detector_3_time_differentiate_input': [],\n",
        "                'detector_1_2_similarity_input': [],\n",
        "                'detector_1_3_similarity_input': [],\n",
        "                'detector_2_3_similarity_input': [],\n",
        "                'detectors_time_input': []\n",
        "            }\n",
        "            for path in X_path:\n",
        "                # load the numpy arrays into memory\n",
        "                data = np.load(path)\n",
        "\n",
        "                # enrich and preprocess the data\n",
        "                if self.model_class == 'dcb':\n",
        "                    time_inputs, frequency_inputs, time_differentiate_inputs, similarity_inputs = self.preprocess(data)\n",
        "                    inputs['detector_1_time_input'].append(time_inputs[0])\n",
        "                    inputs['detector_2_time_input'].append(time_inputs[1])\n",
        "                    inputs['detector_3_time_input'].append(time_inputs[2])\n",
        "                    inputs['detector_1_frequency_input'].append(frequency_inputs[0])\n",
        "                    inputs['detector_2_frequency_input'].append(frequency_inputs[1])\n",
        "                    inputs['detector_3_frequency_input'].append(frequency_inputs[2])\n",
        "                    inputs['detector_1_time_differentiate_input'].append(time_differentiate_inputs[0])\n",
        "                    inputs['detector_2_time_differentiate_input'].append(time_differentiate_inputs[1])\n",
        "                    inputs['detector_3_time_differentiate_input'].append(time_differentiate_inputs[2])\n",
        "                    inputs['detector_1_2_similarity_input'].append(similarity_inputs[0])\n",
        "                    inputs['detector_1_3_similarity_input'].append(similarity_inputs[1])\n",
        "                    inputs['detector_2_3_similarity_input'].append(similarity_inputs[2])\n",
        "                elif self.model_class == 'ccb':\n",
        "                    time_inputs, frequency_inputs, time_differentiate_inputs, similarity_inputs = self.preprocess(data)\n",
        "                    inputs['detector_1_time_input'].append(np.transpose(time_inputs[0]))\n",
        "                    inputs['detector_2_time_input'].append(np.transpose(time_inputs[1]))\n",
        "                    inputs['detector_3_time_input'].append(np.transpose(time_inputs[2]))\n",
        "                    inputs['detector_1_frequency_input'].append(np.transpose(frequency_inputs[0]))\n",
        "                    inputs['detector_2_frequency_input'].append(np.transpose(frequency_inputs[1]))\n",
        "                    inputs['detector_3_frequency_input'].append(np.transpose(frequency_inputs[2]))\n",
        "                    inputs['detector_1_time_differentiate_input'].append(np.transpose(time_differentiate_inputs[0]))\n",
        "                    inputs['detector_2_time_differentiate_input'].append(np.transpose(time_differentiate_inputs[1]))\n",
        "                    inputs['detector_3_time_differentiate_input'].append(np.transpose(time_differentiate_inputs[2]))\n",
        "                    inputs['detector_1_2_similarity_input'].append(np.transpose(similarity_inputs[0]))\n",
        "                    inputs['detector_1_3_similarity_input'].append(np.transpose(similarity_inputs[1]))\n",
        "                    inputs['detector_2_3_similarity_input'].append(np.transpose(similarity_inputs[2]))\n",
        "                    inputs['detectors_time_input'].append(np.transpose(np.array([\n",
        "                        np.squeeze(time_inputs[0]),\n",
        "                        np.squeeze(time_inputs[1]),\n",
        "                        np.squeeze(time_inputs[2])\n",
        "                    ])))\n",
        "\n",
        "            # convert all inputs to numpy arrays\n",
        "            for key, array in inputs.items():\n",
        "                inputs[key] = np.asarray(array, dtype='float64')\n",
        "\n",
        "            return inputs\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            label = self.labels[index * self.batch_size: (index + 1) * self.batch_size]\n",
        "            inputs = self._yield_ish(index)\n",
        "            return inputs, label\n",
        "\n",
        "        def __len__(self):\n",
        "            return self.nb_inputs // self.batch_size\n",
        "\n",
        "        def preprocess(self, data):\n",
        "\n",
        "            # Get each detector time domain vector\n",
        "            detector_1_input_time_vector = np.asarray(data[0])\n",
        "            detector_2_input_time_vector = np.asarray(data[1])\n",
        "            detector_3_input_time_vector = np.asarray(data[2])\n",
        "\n",
        "            # Convert time vectors to frequency domain\n",
        "            detector_1_input_frequency_vector = time_to_frequency(detector_1_input_time_vector, SAMPLE_RATE)\n",
        "            detector_2_input_frequency_vector = time_to_frequency(detector_2_input_time_vector, SAMPLE_RATE)\n",
        "            detector_3_input_frequency_vector = time_to_frequency(detector_3_input_time_vector, SAMPLE_RATE)\n",
        "\n",
        "            # Calculate time first degree differentiate\n",
        "            detector_1_time_differentiate_vector = numerical_differentiation(detector_1_input_time_vector)\n",
        "            detector_2_time_differentiate_vector = numerical_differentiation(detector_2_input_time_vector)\n",
        "            detector_3_time_differentiate_vector = numerical_differentiation(detector_3_input_time_vector)\n",
        "\n",
        "            # Calculate similarity vectors\n",
        "            detector_1_2_similarity_vector = detector_1_input_time_vector - detector_2_input_time_vector\n",
        "            detector_1_3_similarity_vector = detector_1_input_time_vector - detector_3_input_time_vector\n",
        "            detector_2_3_similarity_vector = detector_2_input_time_vector - detector_3_input_time_vector\n",
        "\n",
        "            # Normalize time domain vectors\n",
        "            detector_1_input_time_vector_scaled = self.scalers[\"time_domain\"][0].transform(\n",
        "                detector_1_input_time_vector.reshape(1, -1))\n",
        "            detector_2_input_time_vector_scaled = self.scalers[\"time_domain\"][1].transform(\n",
        "                detector_2_input_time_vector.reshape(1, -1))\n",
        "            detector_3_input_time_vector_scaled = self.scalers[\"time_domain\"][2].transform(\n",
        "                detector_3_input_time_vector.reshape(1, -1))\n",
        "            time_vector_scaled_tuple = (\n",
        "                detector_1_input_time_vector_scaled.reshape(1, -1),\n",
        "                detector_2_input_time_vector_scaled.reshape(1, -1),\n",
        "                detector_3_input_time_vector_scaled.reshape(1, -1)\n",
        "            )\n",
        "\n",
        "            # Normalize frequency domain vectors\n",
        "            detector_1_input_frequency_vector_scaled = self.scalers[\"frequency_domain\"][0].transform(\n",
        "                detector_1_input_frequency_vector.reshape(1, -1))\n",
        "            detector_2_input_frequency_vector_scaled = self.scalers[\"frequency_domain\"][1].transform(\n",
        "                detector_2_input_frequency_vector.reshape(1, -1))\n",
        "            detector_3_input_frequency_vector_scaled = self.scalers[\"frequency_domain\"][2].transform(\n",
        "                detector_3_input_frequency_vector.reshape(1, -1))\n",
        "            frequency_vector_scaled_tuple = (\n",
        "                detector_1_input_frequency_vector_scaled.reshape(1, -1),\n",
        "                detector_2_input_frequency_vector_scaled.reshape(1, -1),\n",
        "                detector_3_input_frequency_vector_scaled.reshape(1, -1)\n",
        "            )\n",
        "\n",
        "            # Normalize differentiated curve\n",
        "            detector_1_time_differentiate_vector_scaled = self.scalers[\"time_differentiate\"][0].transform(\n",
        "                detector_1_time_differentiate_vector.reshape(1, -1))\n",
        "            detector_2_time_differentiate_vector_scaled = self.scalers[\"time_differentiate\"][1].transform(\n",
        "                detector_2_time_differentiate_vector.reshape(1, -1))\n",
        "            detector_3_time_differentiate_vector_scaled = self.scalers[\"time_differentiate\"][2].transform(\n",
        "                detector_3_time_differentiate_vector.reshape(1, -1))\n",
        "            time_differentiate_scaled_tuple = (\n",
        "                detector_1_time_differentiate_vector_scaled.reshape(1, -1),\n",
        "                detector_2_time_differentiate_vector_scaled.reshape(1, -1),\n",
        "                detector_3_time_differentiate_vector_scaled.reshape(1, -1)\n",
        "            )\n",
        "\n",
        "            # Normalize similarity curve\n",
        "            detector_1_2_similarity_vector_scaled = self.scalers['similarity'][0].transform(\n",
        "                detector_1_2_similarity_vector.reshape(1, -1))\n",
        "            detector_1_3_similarity_vector_scaled = self.scalers['similarity'][1].transform(\n",
        "                detector_1_3_similarity_vector.reshape(1, -1))\n",
        "            detector_2_3_similarity_vector_scaled = self.scalers['similarity'][2].transform(\n",
        "                detector_2_3_similarity_vector.reshape(1, -1))\n",
        "            similarity_scaled_tuple = (\n",
        "                detector_1_2_similarity_vector_scaled.reshape(1, -1),\n",
        "                detector_1_3_similarity_vector_scaled.reshape(1, -1),\n",
        "                detector_2_3_similarity_vector_scaled.reshape(1, -1)\n",
        "            )\n",
        "\n",
        "            return time_vector_scaled_tuple, frequency_vector_scaled_tuple, time_differentiate_scaled_tuple, similarity_scaled_tuple\n",
        "\n",
        "        def __next__(self):\n",
        "            if self.n >= self.max:\n",
        "                self.n = 0\n",
        "            result = self.__getitem__(self.n)\n",
        "            self.n += 1\n",
        "            return result"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-05-05T08:51:33.288161Z",
          "iopub.execute_input": "2024-05-05T08:51:33.28851Z",
          "iopub.status.idle": "2024-05-05T08:51:33.34355Z",
          "shell.execute_reply.started": "2024-05-05T08:51:33.288464Z",
          "shell.execute_reply": "2024-05-05T08:51:33.34266Z"
        },
        "trusted": true,
        "id": "MZk40Q1i-hDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Technical challenge - multiprocessing\n",
        "\n",
        "Maybe the second most useful takeout of this misery, it was rather instructive to implement multiprocessing like this, it still may be a good tool to have in future work."
      ],
      "metadata": {
        "id": "Z_Plk_Wd-hDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiprocess functions\n",
        "\n",
        "def multiprocess_functions(combinations: list, kwargs: dict):\n",
        "    active_process_count = 0\n",
        "    queue = SimpleQueue()\n",
        "    processes = []\n",
        "    results = []\n",
        "    while len(combinations) > 0 or len(processes) > 0:\n",
        "        if not queue.empty():\n",
        "            combination, history, process_pid = queue.get()\n",
        "            results.append((combination, history))\n",
        "            processes.remove(process_pid)\n",
        "            try:\n",
        "                process = psutil.Process(process_pid)\n",
        "                process.kill()\n",
        "            except psutil.NoSuchProcess as nsp:\n",
        "                continue\n",
        "            active_process_count -= 1\n",
        "        if len(combinations) > 0 and active_process_count < simultaneous_processes_limit:\n",
        "            combination = combinations.pop(0)\n",
        "            process = CustomProcess(queue, kwargs, combination)\n",
        "            process.start()\n",
        "            active_process_count += 1\n",
        "            processes.append(process.pid)\n",
        "    return results"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T08:51:33.345518Z",
          "iopub.execute_input": "2024-05-05T08:51:33.345804Z",
          "iopub.status.idle": "2024-05-05T08:51:33.358103Z",
          "shell.execute_reply.started": "2024-05-05T08:51:33.345755Z",
          "shell.execute_reply": "2024-05-05T08:51:33.357306Z"
        },
        "trusted": true,
        "id": "bURHN_6n-hDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Needless to say that all these approaches failed, as I missed the most important element in the dataset description: « Each time series contains either detector noise or detector noise plus a simulated gravitational wave signal ».**"
      ],
      "metadata": {
        "id": "lPkzEOUk-hDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understand the data\n",
        "\n",
        "Somehow I forgot that documentation steps are key, and trust me I will not again. To step out of this bad start I had to go through a lot of materials, mostly about signal processing which I had not done in years (whitening, filters, Fourier and Gabor transforms, windowing and wavelets). Just a small reminder that I cited those who helped me the most at the beginning of this notebook."
      ],
      "metadata": {
        "id": "eK0DefzI-hDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What does the data look like now ?\n",
        "\n",
        "Here are the preprocessing steps that were applied to the data.\n",
        "\n",
        "* Windowing : Correct spectral leakage effects when computing the Fourier coefficients with the FFT.\n",
        "* Whitening : Improve signal quality regarding noise.\n",
        "* Filtering : Focus on the interesting part of the signal and reduce data dimension.\n",
        "* Spectrogram : Translate simultaneously the time domain signal into a time and frequency representation.\n",
        "* Image : A simple way to group all 3 detectors into a single piece of data for models, and easy to visualize for humans."
      ],
      "metadata": {
        "id": "G1xcIhEN-hDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- PREPROCESSING FUNCTIONS --------------------\n",
        "\n",
        "# Whitening the signal using PSD\n",
        "def whitening(signal, n, dt):\n",
        "    fhat = np.fft.fft(signal, n)\n",
        "    psd = fhat * np.conj(fhat) / n\n",
        "    freq = 1/(dt*n) * np.arange(n)\n",
        "    interpolated_psd = interp1d(freq, psd, \"nearest\")\n",
        "    w_fhat = fhat / np.sqrt(interpolated_psd(freq))\n",
        "    w_signal = np.fft.ifft(w_fhat)\n",
        "    return w_signal\n",
        "\n",
        "\n",
        "# Prevent spectral leakage using a window function\n",
        "def windowing(signal, n, get_tukey=False):\n",
        "    if get_tukey:\n",
        "        window = tukey(n)\n",
        "    else:\n",
        "        window = hamming(n)\n",
        "    windowed_signal = signal * window\n",
        "    return windowed_signal\n",
        "\n",
        "\n",
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    sos = butter(order, [low, high], btype='band', output='sos')\n",
        "    return sos\n",
        "\n",
        "\n",
        "def butter_bandpass_filter(data, sr, lowcut, highcut):\n",
        "    FILT_SOS = butter_bandpass(lowcut, highcut, sr, order=7)\n",
        "    y = sosfiltfilt(FILT_SOS, data, padlen=1024)\n",
        "    return y\n",
        "\n",
        "# Preprocess the noisy signal\n",
        "def preprocess_signal(signal, sr, fband):\n",
        "    time_span = 2  # seconds\n",
        "    n = time_span * sr  # total number of points\n",
        "    dt = 1 / n\n",
        "    windowed_signal = windowing(signal, n, True)\n",
        "    whitened_signal = whitening(windowed_signal, n, dt)\n",
        "    bandpassed_signal = butter_bandpass_filter(whitened_signal, sr, fband[0], fband[1])\n",
        "    return bandpassed_signal\n",
        "\n",
        "\n",
        "# Transform a signal into its spectrogram\n",
        "def get_spectrogram_img_fmt(signal, sr, nperseg, nfft, noverlap, windowing=False):\n",
        "    if windowing:\n",
        "        mpl_specgram_window = plt.mlab.window_hanning(np.ones(nperseg))\n",
        "        f, t, Sxx = spectrogram(signal, fs=sr, nperseg=nperseg, nfft=nfft, noverlap=noverlap, detrend=False, mode='psd',\n",
        "                                return_onesided=False, window=mpl_specgram_window)\n",
        "    else:\n",
        "\n",
        "        f, t, Sxx = spectrogram(signal, fs=sr, nperseg=nperseg, nfft=nfft, noverlap=noverlap, detrend=False, mode='psd',\n",
        "                                return_onesided=False)\n",
        "\n",
        "    # keep real part of the spectrogram (second half in this implementation)\n",
        "    os_f = f[: len(f)//2]\n",
        "    os_Sxx = np.asarray(Sxx[:len(f)//2, :])\n",
        "\n",
        "    # Normalize values\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(os_Sxx)\n",
        "    scaled_os_Sxx = scaler.transform(os_Sxx)\n",
        "\n",
        "    return os_f, t, scaled_os_Sxx\n",
        "\n",
        "\n",
        "# Return an image sized 3-channels spectrogram as RGB (all 3 detectors)\n",
        "def get_img(file_path):\n",
        "\n",
        "    sr = 2048\n",
        "    fband = [20, 500]\n",
        "    nperseg = 256\n",
        "    nfft = 1024\n",
        "    noverlap = 244\n",
        "    windowing = True\n",
        "\n",
        "    # load a numpy file\n",
        "    signals = np.load(file_path.numpy())\n",
        "\n",
        "    # preprocess all 3 detectors signals\n",
        "    preprocessed_signals = []\n",
        "    for signal in signals:\n",
        "        preprocessed_signal = preprocess_signal(signal, sr, fband)\n",
        "        preprocessed_signals.append(preprocessed_signal)\n",
        "\n",
        "    # build spectrogram array from scratch\n",
        "    f, _, spec1 = get_spectrogram_img_fmt(preprocessed_signals[0], sr, nperseg, nfft, noverlap, windowing)\n",
        "    _, _, spec2 = get_spectrogram_img_fmt(preprocessed_signals[1], sr, nperseg, nfft, noverlap, windowing)\n",
        "    _, _, spec3 = get_spectrogram_img_fmt(preprocessed_signals[2], sr, nperseg, nfft, noverlap, windowing)\n",
        "\n",
        "    # cut out the filtered parts of the signal\n",
        "    lowcut, highcut = fband\n",
        "    lowcut_ind = np.where(f < lowcut)[0][-1]\n",
        "    highcut_ind = np.where(f > highcut)[0][0]\n",
        "    spec1 = spec1[lowcut_ind:highcut_ind, :]\n",
        "    spec2 = spec2[lowcut_ind:highcut_ind, :]\n",
        "    spec3 = spec3[lowcut_ind:highcut_ind, :]\n",
        "    rgb_img = stack([spec1, spec2, spec3], axis=2)\n",
        "\n",
        "    # Format the image to correct input dimensions for CNN\n",
        "    resized_img = resize(rgb_img, INPUT_DIM, anti_aliasing=True)\n",
        "\n",
        "    return resized_img\n",
        "\n",
        "\n",
        "# Preprocess inputs for the tensorflow Dataset pipeline\n",
        "def preprocess(path, label=None):\n",
        "    [image] = tf.py_function(func=get_img, inp=[path], Tout=[tf.float32])\n",
        "    image = tf.ensure_shape(image, INPUT_DIM)\n",
        "    if label is None:\n",
        "        return image\n",
        "    else:\n",
        "        return image, label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T08:51:33.35948Z",
          "iopub.execute_input": "2024-05-05T08:51:33.359731Z",
          "iopub.status.idle": "2024-05-05T08:51:33.388914Z",
          "shell.execute_reply.started": "2024-05-05T08:51:33.3597Z",
          "shell.execute_reply": "2024-05-05T08:51:33.387847Z"
        },
        "trusted": true,
        "id": "FFsPTS_5-hDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random examples of targets preprocessed images\n",
        "\n",
        "![wave_signals_data_v1.png](attachment:771ce774-949d-4e95-a342-3c25568e50c9.png)\n",
        "\n",
        "This time we are training on data that looks more legit ! Notice that the spike shape of targets seems familiar, just like the ones presented in the actual data of gravitational wave signals. Although, you can see in the panel of images above this paragraph that when picked randomly, some of the wave signals are very much alike noise signals (no spike). This could be an interesting point to check in the results, can we successfully classify both the obvious spike images and the not so obvious ones ?"
      ],
      "metadata": {
        "id": "dt5lown4-hDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic CNN\n",
        "\n",
        "Ok this time let’s start simple with a trusted weapon, a good old fashion CNN.\n",
        "\n",
        "For the data pipeline, I used a training set (25% split for validation) structured as a tensorflow Dataset. Preprocessing is done on the fly."
      ],
      "metadata": {
        "id": "cCXre001-hDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CCB3:\n",
        "\n",
        "    def __init__(self, feature, input_shape, batch_size, kernel_size, learning_rate, train_generator,\n",
        "                 validation_generator, epochs):\n",
        "        self.feature = feature\n",
        "        self.input_shape = input_shape\n",
        "        self.batch_size = batch_size\n",
        "        self.kernel_size = kernel_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.train_generator = train_generator\n",
        "        self.validation_generator = validation_generator\n",
        "        self.epochs = epochs\n",
        "        self.model = self._build()\n",
        "\n",
        "    def _build(self):\n",
        "        input_layer = Input(shape=self.input_shape, name=self.feature, batch_size=self.batch_size)\n",
        "\n",
        "        conv_1_layer = Conv2D(filters=16, kernel_size=self.kernel_size, activation='relu')(input_layer)\n",
        "        mp_1_layer = MaxPooling2D(pool_size=2)(conv_1_layer)\n",
        "\n",
        "        conv_2_layer = Conv2D(filters=32, kernel_size=self.kernel_size, activation='relu')(mp_1_layer)\n",
        "        mp_2_layer = MaxPooling2D(pool_size=2)(conv_2_layer)\n",
        "\n",
        "        conv_3_layer = Conv2D(filters=64, kernel_size=self.kernel_size, activation='relu')(mp_2_layer)\n",
        "        mp_3_layer = MaxPooling2D(pool_size=2)(conv_3_layer)\n",
        "\n",
        "        flatten_layer = Flatten()(mp_3_layer)\n",
        "        dense_1_layer = Dense(units=512, activation='relu')(flatten_layer)\n",
        "        dense_2_layer = Dense(units=64, activation='relu')(dense_1_layer)\n",
        "\n",
        "        output_layer = Dense(units=1, activation='sigmoid')(dense_2_layer)\n",
        "\n",
        "        model = Model(input_layer, output_layer)\n",
        "        optimizer = Adam(learning_rate=self.learning_rate)\n",
        "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self):\n",
        "        history = self.model.fit(self.train_generator, epochs=self.epochs, validation_data=self.validation_generator)\n",
        "        return history\n",
        "\n",
        "    def save(self, name: str):\n",
        "        self.model.save(name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T08:51:33.390251Z",
          "iopub.execute_input": "2024-05-05T08:51:33.390916Z",
          "iopub.status.idle": "2024-05-05T08:51:33.406498Z",
          "shell.execute_reply.started": "2024-05-05T08:51:33.390869Z",
          "shell.execute_reply": "2024-05-05T08:51:33.405581Z"
        },
        "trusted": true,
        "id": "sH9QQO3N-hDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- PIPELINE --------------------\n",
        "\n",
        "all_labels = pd.read_csv(labels_path)\n",
        "files_ids = all_labels['id']\n",
        "labels = all_labels['target'].astype('int8').values\n",
        "x_train, x_val, y_train, y_val = train_test_split(files_ids, labels, random_state=42, stratify=labels)\n",
        "x_train = x_train.apply(lambda x: DATA_PATH + '/{}/{}/{}/{}.npy'.format(x[0], x[1], x[2], x))\n",
        "x_val = x_val.apply(lambda x: DATA_PATH + '/{}/{}/{}/{}.npy'.format(x[0], x[1], x[2], x))\n",
        "\n",
        "training_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "training_dataset = training_dataset.map(preprocess, num_parallel_calls=8)\n",
        "training_dataset = training_dataset.batch(batch_size)\n",
        "training_dataset = training_dataset.prefetch(8)\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "validation_dataset = validation_dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "validation_dataset = validation_dataset.batch(batch_size)\n",
        "validation_dataset = validation_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-05-05T08:51:33.407741Z",
          "iopub.execute_input": "2024-05-05T08:51:33.407999Z",
          "iopub.status.idle": "2024-05-05T08:51:38.126163Z",
          "shell.execute_reply.started": "2024-05-05T08:51:33.407966Z",
          "shell.execute_reply": "2024-05-05T08:51:38.125262Z"
        },
        "trusted": true,
        "id": "V9piXuRJ-hDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results\n",
        "\n",
        "Confusion matrix\n",
        "\n",
        "[53223 16794]\n",
        "\n",
        "[28808 41175]\n",
        "\n",
        "* True Positive: 41175 -> 29.410714285714285%\n",
        "* True Negative: 53223 -> 38.01642857142858%\n",
        "* False Positive: 16794 -> 11.995714285714286%\n",
        "* False Negative: 28808 -> 20.577142857142857%\n",
        "\n",
        "\n",
        "**Accuracy** = 67.43%\n",
        "\n",
        "**Precision** =  71.03%\n",
        "\n",
        "**Recall** = 58.84%"
      ],
      "metadata": {
        "id": "iAgW0EpR-hDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-trained CNN\n",
        "\n",
        "I did test both Resnet and EfficientNet, but did not notice a significant difference between their respective results."
      ],
      "metadata": {
        "id": "08MsZFDq-hDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CCB5:\n",
        "\n",
        "    def __init__(self, feature, input_shape, batch_size, kernel_size, learning_rate, train_generator,\n",
        "                 validation_generator, epochs):\n",
        "        self.feature = feature\n",
        "        self.input_shape = input_shape\n",
        "        self.batch_size = batch_size\n",
        "        self.kernel_size = kernel_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.train_generator = train_generator\n",
        "        self.validation_generator = validation_generator\n",
        "        self.epochs = epochs\n",
        "        self.model = self._build()\n",
        "\n",
        "    def _build(self):\n",
        "        input_layer = Input(shape=self.input_shape, name=self.feature, batch_size=self.batch_size)\n",
        "\n",
        "        conv_base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=self.input_shape)(input_layer)\n",
        "        conv_base.trainable = False\n",
        "        gapl = GlobalAveragePooling2D()(conv_base)\n",
        "        output_layer = Dense(units=1, activation='sigmoid')(gapl)\n",
        "\n",
        "        model = Model(input_layer, output_layer)\n",
        "        optimizer = Adam(learning_rate=self.learning_rate)\n",
        "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self):\n",
        "        history = self.model.fit(self.train_generator, epochs=self.epochs, validation_data=self.validation_generator)\n",
        "        return history\n",
        "\n",
        "    def save(self, name: str):\n",
        "        self.model.save(name)\n",
        "\n",
        "    def predict(self):\n",
        "        predictions = self.model.predict(self.validation_generator)\n",
        "        return predictions"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T08:51:38.127424Z",
          "iopub.execute_input": "2024-05-05T08:51:38.127658Z",
          "iopub.status.idle": "2024-05-05T08:51:38.139429Z",
          "shell.execute_reply.started": "2024-05-05T08:51:38.127628Z",
          "shell.execute_reply": "2024-05-05T08:51:38.138608Z"
        },
        "trusted": true,
        "id": "1824Li_F-hDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results\n",
        "\n",
        "Confusion matrix\n",
        "\n",
        "[69813   204]\n",
        "\n",
        "[56291 13692]\n",
        "\n",
        "* True Positive: 13692 -> 9.78%\n",
        "* True Negative: 69813 -> 49.86642857142857%\n",
        "* False Positive: 204 -> 0.1457142857142857%\n",
        "* False Negative: 56291 -> 40.207857142857144%\n",
        "\n",
        "\n",
        "**Accuracy** = 59.65%\n",
        "\n",
        "**Precision** = 98.53%\n",
        "\n",
        "**Recall** = 19.56%\n",
        "\n",
        "![ccb5_1_predictions_distribution.png](attachment:6efea503-9a3e-4e18-9a73-f31c1a9a2453.png)\n",
        "\n",
        "Accuracy is not as high as the basic plain CNN, but I did not optimize the trained layers. I could have also used a GlobalAveragePool layer from the Keras library instead. As for the training result, we obtained an extremely selective model, with almost a perfect precision, but always with the corresponding tradeoff on False Negative that comes with it."
      ],
      "metadata": {
        "id": "VSkx7iS8-hDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions similarity\n",
        "\n",
        "Also I want to check if both models were performant on the same inputs or if they learned different features. In the second scenario, adding an Ensembling step after training these type of models could further improve the results.\n",
        "\n",
        "*-- code below --*"
      ],
      "metadata": {
        "id": "--6YzP4a-hDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_col(a, b):\n",
        "    arr_a = np.array(a)\n",
        "    arr_b = np.array(b)\n",
        "    similarity_count = {\n",
        "        'TP': 0,\n",
        "        'TN': 0,\n",
        "        'FP': 0,\n",
        "        'FN': 0\n",
        "    }\n",
        "    for elem_a, elem_b in zip(arr_a, arr_b):\n",
        "        if elem_a == elem_b == 'TP':\n",
        "            similarity_count['TP'] += 1\n",
        "        elif elem_a == elem_b == 'TN':\n",
        "            similarity_count['TN'] += 1\n",
        "        elif elem_a == elem_b == 'FP':\n",
        "            similarity_count['FP'] += 1\n",
        "        elif elem_a == elem_b == 'FN':\n",
        "            similarity_count['FN'] += 1\n",
        "    return similarity_count\n",
        "\n",
        "\n",
        "def compare_models(name_1: str, name_2: str):\n",
        "    data, paths, labels, model_1 = load_model_and_data(name_1)\n",
        "    _, _, _, model_2 = load_model_and_data(name_2)\n",
        "\n",
        "    # get predictions and predictions labels for both models\n",
        "    predictions_1 = model_1.predict(data)\n",
        "    predictions_2 = model_2.predict(data)\n",
        "    predictions_labels_1 = [1 if p > 0.5 else 0 for p in predictions_1]\n",
        "    predictions_labels_2 = [1 if p > 0.5 else 0 for p in predictions_2]\n",
        "\n",
        "    # get complete labeled dataframe for both models\n",
        "    dataframe_1 = label_df_confusion_matrix(predictions_labels_1, predictions_1, labels, paths)\n",
        "    print(np.unique(np.asarray(dataframe_1['cm']), return_counts=True))\n",
        "    dataframe_2 = label_df_confusion_matrix(predictions_labels_2, predictions_2, labels, paths)\n",
        "    print(np.unique(np.asarray(dataframe_2['cm']), return_counts=True))\n",
        "\n",
        "    # compare similarity of both dataframes regarding TP, TN, FP, FN\n",
        "    similarity = similarity_col(dataframe_1['cm'], dataframe_2['cm'])\n",
        "    for key, value in similarity.items():\n",
        "        print('{}: {}'.format(key, value))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-05-05T08:51:38.14077Z",
          "iopub.execute_input": "2024-05-05T08:51:38.140982Z",
          "iopub.status.idle": "2024-05-05T08:51:38.157714Z",
          "shell.execute_reply.started": "2024-05-05T08:51:38.140955Z",
          "shell.execute_reply": "2024-05-05T08:51:38.157005Z"
        },
        "trusted": true,
        "id": "4cxRKN-2-hDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Results interpretation\n",
        "\n",
        "\n",
        "For the basic CNN we have the following:\n",
        "* FN : 28808\n",
        "* FP : 16794\n",
        "* TN : 53223\n",
        "* TP : 41175\n",
        "\n",
        "And for the pretrained Convnet:\n",
        "* FN : 56291\n",
        "* FP : 204\n",
        "* TN : 69813\n",
        "* TP : 13692\n",
        "\n",
        "Similarity counts of the predictions for each category:\n",
        "* TP: 13673\n",
        "* TN: 53209\n",
        "* FP: 190\n",
        "* FN: 28789\n",
        "\n",
        "Which means that both networks detected the same conclusive features to classify target waves (almost 100% of the pretrained convnet true positives are matched by the basic CNN), but other features used by the CNN are not efficient enough (tradeoff with false positives)."
      ],
      "metadata": {
        "id": "IUp1MOZ1-hDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenging the data again\n",
        "\n",
        "Can we improve the data again ? Obviously yes (see, I learned my lesson), so let’s try it !"
      ],
      "metadata": {
        "id": "gRHywmK--hDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### True Positives overview\n",
        "\n",
        "![wave_signals_data_v2.png](attachment:e1712533-88b3-4ab6-81eb-6dcfef5ec91b.png)\n",
        "\n",
        "### What did I do differently ?\n",
        "\n",
        "* Windowing: tukey window is recommended in the original paper as well as in various other notebooks of the competition.  I used it to replace the hanning window in the signal preprocessing.\n",
        "* Frequencies: I extended the bandpass filter from [35: 350] Hz to [20: 500] Hz in order to take more information in the learning process. Also I activated a window on the segments spectrum computations.\n",
        "* Image (resolution, dimensions): Finally I modified the spectrum computation function to have a higher frequency/time resolution on the final images. I also chose a larger image (from 112x112 to 150x150 pixels). The objective was to capture more information for the model to train better."
      ],
      "metadata": {
        "id": "SZ8BJERy-hDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic CNN\n",
        "\n",
        "epoch 1\n",
        "***\n",
        "*2100/2100 [==============================] - ETA: 0s - loss: 0.5496 - acc: 0.70032022-04-19 23:35:23.004577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.*\n",
        "\n",
        "*2100/2100 [==============================] - 12927s 6s/step - loss: 0.5496 - acc: 0.7003 - val_loss: 0.5243 - val_acc: 0.7220*\n",
        "***\n",
        "epoch 2\n",
        "***\n",
        "*2100/2100 [==============================] - ETA: 0s - loss: 0.5206 - acc: 0.72392022-04-20 22:43:13.922581: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.*\n",
        "\n",
        "*2100/2100 [==============================] - 11828s 6s/step - loss: 0.5206 - acc: 0.7239 - val_loss: 0.5202 - val_acc: 0.7255*\n",
        "***\n",
        "There does not seem to have a real interest to push training further after the second epoch.\n",
        "\n",
        "![prediction_distribution_ccb3_3.png](attachment:97a11f8e-d31c-4c2d-9c91-ab3cd8725330.png)\n",
        "\n",
        "#### Results\n",
        "\n",
        "Confusion matrix\n",
        "\n",
        "[56864 13153]\n",
        "\n",
        "[25277 44706]\n",
        "\n",
        "* True Positive: 44706 -> 31.93285714285714%\n",
        "* True Negative: 56864 -> 40.61714285714286%\n",
        "* False Positive: 13153 -> 9.395000000000001%\n",
        "* False Negative: 25277 -> 18.055%\n",
        "\n",
        "**Accuracy** = 72.55%\n",
        "\n",
        "**Precision** = 77.27%\n",
        "\n",
        "**Recall** = 63.88%"
      ],
      "metadata": {
        "id": "6Ez52Bfa-hDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-trained CNN\n",
        "\n",
        "This time let’s show you the results for the Resnet50v2.\n",
        "\n",
        "epoch 1\n",
        "***\n",
        "*2100/2100 [==============================] - ETA: 0s - loss: 0.5263 - acc: 0.71912022-04-22 20:41:52.003715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.*\n",
        "\n",
        "*2100/2100 [==============================] - 12114s 6s/step - loss: 0.5263 - acc: 0.7191 - val_loss: 0.5200 - val_acc: 0.7275*\n",
        "***\n",
        "\n",
        "**Accuracy** = 72.75%\n",
        "\n",
        "As we are getting roughly the same score as the plain CNN model, I decided not to continue training based on the assumption that results will not likely improve much."
      ],
      "metadata": {
        "id": "7j4QgAcU-hDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Were the updates successful ? With respectively a solid 5% and 13% accuracy increase for each model, I would say yes !**"
      ],
      "metadata": {
        "id": "qi-ldRkA-hDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Follow up steps\n",
        "\n",
        "* Use other features extraction methods (such as wavelets) that seem to perform better for our problem.\n",
        "* Further preprocess data. As we saw on the images, some signals are still drawning in noise. For example use zero padding, fine tune parameters, or even image post-processing."
      ],
      "metadata": {
        "id": "pFYoVf4d-hDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "That was the most complicated dataset I have worked on so far on Kaggle, and it was definitely not easy.\n",
        "\n",
        "I got to learn a lot about signal processing, and also had a very brutal reminder about machine learning methodology.\n",
        "\n",
        "\"Machine learning is not magic, if you feed it crap it will give you the exact same in return.\"\n",
        "\n",
        "I am satisfied with my final results, since I was stuck for a long time. There is yet a great margin for improvement, as top accuracies on this competition go up to over 85%."
      ],
      "metadata": {
        "id": "FPrpbbY6-hDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "uJG7hdwl-hDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------- SUBMISSION --------------------\n",
        "sample_submission = pd.read_csv('../input/g2net-gravitational-wave-detection/sample_submission.csv')\n",
        "\n",
        "def prep_submission():\n",
        "\n",
        "    # Load trained model\n",
        "    model = load_model('../input/g2net-model/ccb3_4/ccb3_4')\n",
        "\n",
        "    # Calculate predictions in batches\n",
        "    pred_batch = 22600\n",
        "\n",
        "    for i in range(10):\n",
        "\n",
        "        submission_files_ids = sample_submission['id'][i*pred_batch:(i+1)*pred_batch]\n",
        "        x_test = submission_files_ids.apply(lambda x: submission_data_path + '/{}/{}/{}/{}.npy'.format(x[0], x[1], x[2], x))\n",
        "\n",
        "        test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n",
        "        test_dataset = test_dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        test_dataset = test_dataset.batch(batch_size)\n",
        "        test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "        partial_predictions = model.predict(test_dataset, verbose=1)\n",
        "        np.save('partial_submission_{}'.format(i), partial_predictions)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T08:51:38.160051Z",
          "iopub.execute_input": "2024-05-05T08:51:38.160294Z",
          "iopub.status.idle": "2024-05-05T08:51:38.373407Z",
          "shell.execute_reply.started": "2024-05-05T08:51:38.160263Z",
          "shell.execute_reply": "2024-05-05T08:51:38.372682Z"
        },
        "trusted": true,
        "id": "h7YhXyk--hDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate all predictions\n",
        "sample_submission_dir = '../input/g2netpartialsubmission'\n",
        "predictions = None\n",
        "for sample_submission_path in os.listdir(sample_submission_dir):\n",
        "    sample_sub = np.load(os.path.join(sample_submission_dir, sample_submission_path))\n",
        "    if predictions is None:\n",
        "        predictions = sample_sub\n",
        "    else:\n",
        "        predictions = np.concatenate((predictions, sample_sub), axis=None)\n",
        "\n",
        "# Make submission dataframe\n",
        "submission = pd.DataFrame({'id': sample_submission['id'], 'target': predictions})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T08:51:38.374547Z",
          "iopub.execute_input": "2024-05-05T08:51:38.374794Z",
          "iopub.status.idle": "2024-05-05T08:51:38.802638Z",
          "shell.execute_reply.started": "2024-05-05T08:51:38.374763Z",
          "shell.execute_reply": "2024-05-05T08:51:38.801487Z"
        },
        "trusted": true,
        "id": "EvS33vjQ-hDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit\n",
        "submission.to_csv('./submission.csv', index= False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-05T08:51:38.803853Z",
          "iopub.status.idle": "2024-05-05T08:51:38.80431Z",
          "shell.execute_reply.started": "2024-05-05T08:51:38.804077Z",
          "shell.execute_reply": "2024-05-05T08:51:38.804104Z"
        },
        "trusted": true,
        "id": "PgJoP-WK-hDt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}