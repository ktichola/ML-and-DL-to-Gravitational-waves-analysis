{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 823552,
          "sourceType": "datasetVersion",
          "datasetId": 433366
        }
      ],
      "dockerImageVersionId": 30498,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktichola/ML-and-DL-to-Gravitational-waves-analysis/blob/main/%CE%91%CE%BD%CF%84%CE%AF%CE%B3%CF%81%CE%B1%CF%86%CE%BF_Kyriaki_3_Gravity_Spy_Vision_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'gravity-spy-gravitational-waves:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F433366%2F823552%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240506%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240506T082340Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0376ccb18e1bcbad8ed8fa106fb3f1b782af807dda0d2074d0647b6779f45a415d3a9ffb93a1fc3d12b7a678e5dc9b685e2d0249fc4f80c101627cd66ee0766e6a7554ea9941a793ec32177de2378aa8b9b7fdc748b205bac010544ad76856f6aa06c7648f1b60d183257429863aad076ab0e0f7481fc47245ec6b900538dd6606b9e5c7403c628be6c43e09461a801c51ffea622a5e9cf692c2cff66154ce5399d70911ac86d23010bb8f5e60331493f46b274a9641959c255e35e90111c5aebf56c219ad6233474ba34b767d0fdb2e1533f7bb9be0d1cf7388b43f447f4acf85a8e1fa7bdcce95962520dc63f49df4ae9e409b1fe28af1765b329778b42481'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "KHCOqIMcAGLs"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip install einops"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:13:05.785065Z",
          "iopub.execute_input": "2024-05-06T08:13:05.785495Z",
          "iopub.status.idle": "2024-05-06T08:13:19.399626Z",
          "shell.execute_reply.started": "2024-05-06T08:13:05.785461Z",
          "shell.execute_reply": "2024-05-06T08:13:19.397717Z"
        },
        "trusted": true,
        "id": "vbZO1mxKAGLu",
        "outputId": "f48b508a-f6d7-43bb-9964-9b4f385769c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting einops\n  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from einops import repeat\n",
        "from einops.layers.torch import Rearrange"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:13:19.402139Z",
          "iopub.execute_input": "2024-05-06T08:13:19.402545Z",
          "iopub.status.idle": "2024-05-06T08:13:24.828152Z",
          "shell.execute_reply.started": "2024-05-06T08:13:19.402511Z",
          "shell.execute_reply": "2024-05-06T08:13:24.826909Z"
        },
        "trusted": true,
        "id": "Eu31iPqUAGLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "     transforms.Resize((32,32)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, ), (0.5,))\n",
        "    ])\n",
        "\n",
        "\n",
        "train_image_dir = '../input/gravity-spy-gravitational-waves/train/train/'\n",
        "val_image_dir = '../input//gravity-spy-gravitational-waves/validation/validation/'\n",
        "test_image_dir = '../input//gravity-spy-gravitational-waves/test/test/'\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:13:24.829793Z",
          "iopub.execute_input": "2024-05-06T08:13:24.830942Z",
          "iopub.status.idle": "2024-05-06T08:13:24.837185Z",
          "shell.execute_reply.started": "2024-05-06T08:13:24.830898Z",
          "shell.execute_reply": "2024-05-06T08:13:24.835968Z"
        },
        "trusted": true,
        "id": "0tYv88wwAGLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.ImageFolder(root=train_image_dir, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "\n",
        "validation_set = torchvision.datasets.ImageFolder(root=val_image_dir, transform=transform)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=16,\n",
        "                                         shuffle=False)\n",
        "\n",
        "test_set = torchvision.datasets.ImageFolder(root=test_image_dir, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:13:24.839951Z",
          "iopub.execute_input": "2024-05-06T08:13:24.840397Z",
          "iopub.status.idle": "2024-05-06T08:14:01.445606Z",
          "shell.execute_reply.started": "2024-05-06T08:13:24.840359Z",
          "shell.execute_reply": "2024-05-06T08:14:01.444226Z"
        },
        "trusted": true,
        "id": "vqluW2HxAGLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Patching(nn.Module):\n",
        "    def __init__(self, patch_size):\n",
        "\n",
        "        super().__init__()\n",
        "        self.net = Rearrange(\"b c (h ph) (w pw) -> b (h w) (ph pw c)\", ph = patch_size, pw = patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class LinearProjection(nn.Module):\n",
        "    def __init__(self, patch_dim, dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Linear(patch_dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:14:01.447092Z",
          "iopub.execute_input": "2024-05-06T08:14:01.447461Z",
          "iopub.status.idle": "2024-05-06T08:14:01.455884Z",
          "shell.execute_reply.started": "2024-05-06T08:14:01.447432Z",
          "shell.execute_reply": "2024-05-06T08:14:01.454409Z"
        },
        "trusted": true,
        "id": "Fc13xbyNAGLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, dim, n_patches):\n",
        "        super().__init__()\n",
        "        # [class] token\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "\n",
        "        # position embedding\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, n_patches + 1, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, _, __ = x.shape\n",
        "\n",
        "\n",
        "        # x.shape : [batch_size, n_patches, patch_dim] -> [batch_size, n_patches + 1, patch_dim]\n",
        "        cls_tokens = repeat(self.cls_token, \"1 1 d -> b 1 d\", b = batch_size)\n",
        "        x = torch.concat([cls_tokens, x], dim = 1)\n",
        "\n",
        "        x += self.pos_embedding\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:14:01.457395Z",
          "iopub.execute_input": "2024-05-06T08:14:01.457807Z",
          "iopub.status.idle": "2024-05-06T08:14:01.469967Z",
          "shell.execute_reply.started": "2024-05-06T08:14:01.457775Z",
          "shell.execute_reply": "2024-05-06T08:14:01.468754Z"
        },
        "trusted": true,
        "id": "MPpqZ_0-AGLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, dim, n_heads):\n",
        "        super().__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.dim_heads = dim // n_heads\n",
        "\n",
        "        self.W_q = nn.Linear(dim, dim)\n",
        "        self.W_k = nn.Linear(dim, dim)\n",
        "        self.W_v = nn.Linear(dim, dim)\n",
        "\n",
        "        self.split_into_heads = Rearrange(\"b n (h d) -> b h n d\", h = self.n_heads)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim = -1)\n",
        "\n",
        "        self.concat = Rearrange(\"b h n d -> b n (h d)\", h = self.n_heads)\n",
        "\n",
        "    def forward(self, x):\n",
        "        q = self.W_q(x)\n",
        "        k = self.W_k(x)\n",
        "        v = self.W_v(x)\n",
        "\n",
        "        q = self.split_into_heads(q)\n",
        "        k = self.split_into_heads(k)\n",
        "        v = self.split_into_heads(v)\n",
        "\n",
        "        # Logit[i] = Q[i] * tK[i] / sqrt(D) (i = 1, ... , n_heads)\n",
        "        # AttentionWeight[i] = Softmax(Logit[i]) (i = 1, ... , n_heads)\n",
        "        logit = torch.matmul(q, k.transpose(-1, -2)) * (self.dim_heads ** -0.5)\n",
        "        attention_weight = self.softmax(logit)\n",
        "\n",
        "        # Head[i] = AttentionWeight[i] * V[i] (i = 1, ... , n_heads)\n",
        "        # Output = concat[Head[1], ... , Head[n_heads]]\n",
        "        output = torch.matmul(attention_weight, v)\n",
        "        output = self.concat(output)\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:14:01.471357Z",
          "iopub.execute_input": "2024-05-06T08:14:01.471733Z",
          "iopub.status.idle": "2024-05-06T08:14:01.487113Z",
          "shell.execute_reply.started": "2024-05-06T08:14:01.471693Z",
          "shell.execute_reply": "2024-05-06T08:14:01.486004Z"
        },
        "trusted": true,
        "id": "evNGev8SAGLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, dim, n_heads, mlp_dim, depth):\n",
        "        super().__init__()\n",
        "\n",
        "        # Layers\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.multi_head_attention = MultiHeadAttention(dim = dim, n_heads = n_heads)\n",
        "        self.mlp = MLP(dim = dim, hidden_dim = mlp_dim)\n",
        "        self.depth = depth\n",
        "\n",
        "    def forward(self, x):\n",
        "        for _ in range(self.depth):\n",
        "            x = self.multi_head_attention(self.norm(x)) + x\n",
        "            x = self.mlp(self.norm(x)) + x\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class MLPHead(nn.Module):\n",
        "    def __init__(self, dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:14:01.488689Z",
          "iopub.execute_input": "2024-05-06T08:14:01.490045Z",
          "iopub.status.idle": "2024-05-06T08:14:01.502329Z",
          "shell.execute_reply.started": "2024-05-06T08:14:01.489955Z",
          "shell.execute_reply": "2024-05-06T08:14:01.501483Z"
        },
        "trusted": true,
        "id": "4eW2CZANAGL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Module):\n",
        "    def __init__(self, image_size, patch_size, n_classes, dim, depth, n_heads, channels = 3, mlp_dim = 256):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Params\n",
        "        n_patches = (image_size // patch_size) ** 2\n",
        "        patch_dim = channels * patch_size * patch_size\n",
        "        self.depth = depth\n",
        "\n",
        "        # Layers\n",
        "        self.patching = Patching(patch_size = patch_size)\n",
        "        self.linear_projection_of_flattened_patches = LinearProjection(patch_dim = patch_dim, dim = dim)\n",
        "        self.embedding = Embedding(dim = dim, n_patches = n_patches)\n",
        "        self.transformer_encoder = TransformerEncoder(dim = dim, n_heads = n_heads, mlp_dim = mlp_dim, depth = depth)\n",
        "        self.mlp_head = MLPHead(dim = dim, out_dim = n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        "\n",
        "        x = img\n",
        "\n",
        "        # x.shape : [batch_size, channels, image_height, image_width] -> [batch_size, n_patches, channels * (patch_size ** 2)]\n",
        "        x = self.patching(x)\n",
        "\n",
        "        # x.shape : [batch_size, n_patches, channels * (patch_size ** 2)] -> [batch_size, n_patches, dim]\n",
        "        x = self.linear_projection_of_flattened_patches(x)\n",
        "\n",
        "        # x.shape : [batch_size, n_patches, dim] -> [batch_size, n_patches + 1, dim]\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # x.shape : No Change\n",
        "        x = self.transformer_encoder(x)\n",
        "\n",
        "        # x.shape : [batch_size, n_patches + 1, dim] -> [batch_size, dim] -> [batch_size, n_classes]\n",
        "        x = x[:, 0]\n",
        "        x = self.mlp_head(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:14:01.503871Z",
          "iopub.execute_input": "2024-05-06T08:14:01.504905Z",
          "iopub.status.idle": "2024-05-06T08:14:01.515635Z",
          "shell.execute_reply.started": "2024-05-06T08:14:01.504862Z",
          "shell.execute_reply": "2024-05-06T08:14:01.514366Z"
        },
        "trusted": true,
        "id": "aru0gkEhAGL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:14:01.518902Z",
          "iopub.execute_input": "2024-05-06T08:14:01.519302Z",
          "iopub.status.idle": "2024-05-06T08:14:01.53347Z",
          "shell.execute_reply.started": "2024-05-06T08:14:01.51927Z",
          "shell.execute_reply": "2024-05-06T08:14:01.532342Z"
        },
        "trusted": true,
        "id": "GOxmCD7oAGL1",
        "outputId": "3788936c-4208-44df-801c-bc7d27a15835"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "cpu\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = ViT(\n",
        "    image_size=32,\n",
        "    patch_size=4,\n",
        "    n_classes=22,\n",
        "    dim=256,\n",
        "    depth=3,\n",
        "    n_heads=4,\n",
        "    mlp_dim = 256\n",
        ").to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:14:01.534696Z",
          "iopub.execute_input": "2024-05-06T08:14:01.535193Z",
          "iopub.status.idle": "2024-05-06T08:14:01.604045Z",
          "shell.execute_reply.started": "2024-05-06T08:14:01.535163Z",
          "shell.execute_reply": "2024-05-06T08:14:01.602522Z"
        },
        "trusted": true,
        "id": "zymZzSIrAGL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:14:01.606426Z",
          "iopub.execute_input": "2024-05-06T08:14:01.607217Z",
          "iopub.status.idle": "2024-05-06T08:14:01.616644Z",
          "shell.execute_reply.started": "2024-05-06T08:14:01.607143Z",
          "shell.execute_reply": "2024-05-06T08:14:01.615051Z"
        },
        "trusted": true,
        "id": "DpuCQYVZAGL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "epochs = 10\n",
        "accuracy=[]\n",
        "losses=[]\n",
        "val_accuracy=[]\n",
        "val_losses=[]\n",
        "sta = time.time()\n",
        "for epoch in range(0, epochs):\n",
        "    epoch_train_loss = 0\n",
        "    epoch_train_acc = 0\n",
        "    epoch_val_loss = 0\n",
        "    epoch_val_acc = 0\n",
        "\n",
        "    net.train()\n",
        "    for data in train_loader:\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_train_loss += loss.item()/len(train_loader)\n",
        "        acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
        "        epoch_train_acc += acc/len(train_loader)\n",
        "\n",
        "        del inputs\n",
        "        del outputs\n",
        "        del loss\n",
        "    accuracy.append(epoch_train_acc)\n",
        "    losses.append(epoch_train_loss)\n",
        "\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in validation_loader:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            epoch_val_loss += loss.item()/len(validation_loader)\n",
        "            val_acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
        "            epoch_val_acc += val_acc/len(validation_loader)\n",
        "        val_accuracy.append(epoch_val_acc)\n",
        "        val_losses.append(epoch_val_loss)\n",
        "\n",
        "    print(\"epoch: {}, loss: {}, acc: {}    \" \\\n",
        "    \"val_epoch: {}, val_loss: {}, val_acc: {}\".format(epoch+1, epoch_train_loss, epoch_train_acc, epoch+1, epoch_val_loss, epoch_val_acc))\n",
        "\n",
        "\n",
        "end= time.time()\n",
        "print(end-sta)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-06T08:14:01.618404Z",
          "iopub.execute_input": "2024-05-06T08:14:01.619184Z"
        },
        "trusted": true,
        "id": "iJu9i0SBAGL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses, label='train loss')\n",
        "plt.plot(val_losses, label='validation loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "trusted": true,
        "id": "_5d16phoAGL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accslist=[]\n",
        "val_accslist=[]\n",
        "for i in range(len(accuracy)):\n",
        "    accslist.append(accuracy[i].item())\n",
        "\n",
        "for i in range(len(val_accuracy)):\n",
        "    val_accslist.append(val_accuracy[i].item())\n",
        "\n",
        "plt.plot(accslist, label='train acc')\n",
        "plt.plot(val_accslist, label='validation acc')\n",
        "plt.legend()"
      ],
      "metadata": {
        "trusted": true,
        "id": "RtPNRCzwAGL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "epoch_test_loss = 0\n",
        "epoch_test_acc = 0\n",
        "pred=[]\n",
        "ans=[]\n",
        "start=time.time()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        epoch_test_loss += loss.item()/len(test_loader)\n",
        "        test_acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
        "        pre =outputs.argmax(dim=1)\n",
        "        pred.append(pre.item())\n",
        "        ans.append(labels.item())\n",
        "        epoch_test_acc += test_acc/len(test_loader)\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)\n",
        "print(\"test_loss: {}, test_acc: {}\".format(epoch_test_loss, epoch_test_acc))"
      ],
      "metadata": {
        "trusted": true,
        "id": "PjMtVpjKAGL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(f1_score(ans, pred,average='weighted'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "yJnb70xOAGL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "files = os.listdir(test_image_dir)\n",
        "print(files)\n",
        "files.sort()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "5-8Lb0qQAGL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "cm = confusion_matrix(ans, pred)\n",
        "cm = pd.DataFrame(data=cm, index=files, columns=files)\n",
        "plt.figure(figsize = (10,7))\n",
        "sns.heatmap(cm,annot=True,cmap='Blues',fmt='d')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ypq92MEdAGL3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}